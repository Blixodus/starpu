# StarPU --- Runtime system for heterogeneous multicore architectures.
#
# Copyright (C) 2020       UniversitÃ© de Bordeaux, CNRS (LaBRI UMR 5800), Inria
#
# StarPU is free software; you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or (at
# your option) any later version.
#
# StarPU is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# See the GNU Lesser General Public License in COPYING.LGPL for more details.
#
from starpu import starpupy
import starpu
import asyncio
import math
import functools

# get the number of CPUs controlled by StarPU
n_cpus=starpupy.cpu_worker_get_count()

# split a list ls into n_block numbers of sub-lists 
def partition(ls, n_block):
	if len(ls)>=n_block:
		# there are n1 sub-lists which contain q1 elements, and (n_block-n1) sublists which contain q2 elements (n1 can be 0)
		q1=math.ceil(len(ls)/n_block)
		q2=math.floor(len(ls)/n_block)
		n1=len(ls)%n_block
		#n2=n_block-n1
		# generate n1 sub-lists in L1, and (n_block-n1) sub-lists in L2
		L1=[ls[i:i+q1] for i in range(0, n1*q1, q1)]
		L2=[ls[i:i+q2] for i in range(n1*q1, len(ls), q2)]

		L=L1+L2
	else:
		# if the block number is larger than the length of list, each element in the list is a sub-list
		L=[ls[i:i+1] for i in range (len(ls))]
	return L

def future_generator(g, n_jobs, dict_task):
	# g is generated by delayed function, after converting to a list, the format is [function, (arg1, arg2, ... ,)]
	L=list(g)
	# generate a list of function according to g
	def lf(ls):
		L_func=[]
		for i in range(len(ls)):
			# the first element is the function
			f=ls[i][0]
			# the second element is the args list of a type tuple
			L_args=list(ls[i][1])
			# generate a list of function
			L_func.append(f(*L_args))
		return L_func
	# get the number of block
	if n_jobs<-n_cpus-1 or n_jobs>n_cpus:
		print("Error: n_jobs is out of range, number of CPUs is", n_cpus)
	elif n_jobs<0:
		n_block=n_cpus+1+n_jobs
	else:
		n_block=n_jobs
	# generate the split function list
	L_split=partition(L,n_block)
	# operation in each split list
	L_fut=[]
	for i in range(len(L_split)):
		fut=starpu.task_submit(name=dict_task['name'], synchronous=dict_task['synchronous'], priority=dict_task['priority'],\
							   color=dict_task['color'], flops=dict_task['flops'], perfmodel=dict_task['perfmodel'])\
			                  (lf, L_split[i])
		L_fut.append(fut)
	return L_fut

def parallel(*, mode="normal", n_jobs=1, perfmodel=None, end_msg=None,\
			 name=None, synchronous=0, priority=0, color=None, flops=None,\
	         backend=None, verbose=0, timeout=None, pre_dispatch='2 * n_jobs',\
	         batch_size='auto', temp_folder=None, max_nbytes='1M',\
	         mmap_mode='r', prefer=None, require=None):
	#generate the dictionary of task_submit
	dict_task={'name': name, 'synchronous': synchronous, 'priority': priority, 'color': color, 'flops': flops, 'perfmodel': perfmodel}
	# the mode normal, user can call the function directly without using async
	if mode=="normal":
		def parallel_normal(g):
			async def asy_main():
				L_fut=future_generator(g, n_jobs, dict_task)
				res=[]
				for i in range(len(L_fut)):
					L_res=await L_fut[i]
					res.extend(L_res)
				#print(res)
				return res
			asyncio.run(asy_main())
			return asy_main
		return parallel_normal
	# the mode future, user needs to use asyncio module and await the Future result in main function
	elif mode=="future":
		def parallel_future(g):
			L_fut=future_generator(g, n_jobs, dict_task)
			fut=asyncio.gather(*L_fut)
			if end_msg==None:
				return fut
			else:
				fut.add_done_callback(functools.partial(print, end_msg))
				return fut
			#return fut
		return parallel_future

def delayed(f):
	def delayed_func(*args):
		return f, args
	return delayed_func


######################################################################

